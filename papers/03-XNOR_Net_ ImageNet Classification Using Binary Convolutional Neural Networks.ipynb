{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper name:  [XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks](https://pjreddie.com/media/files/papers/xnor.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Abstract\n",
    "\n",
    "We propose **two efficient approximations** to standard convolutional\n",
    "neural networks: **Binary-Weight-Networks** and **XNOR-Networks**. In Binary-WeightNetworks,\n",
    "the filters are approximated with binary values resulting in 32× memory\n",
    "saving. In XNOR-Networks, both the filters and the input to convolutional\n",
    "layers are binary. XNOR-Networks approximate convolutions using primarily binary\n",
    "operations. This results in 58× faster convolutional operations and 32×\n",
    "memory savings. XNOR-Nets offer the possibility of running state-of-the-art\n",
    "networks on CPUs (rather than GPUs) in real-time. Our binary networks are\n",
    "simple, accurate, efficient, and work on challenging visual tasks. We evaluate\n",
    "our approach on the ImageNet classification task. The classification accuracy\n",
    "with a Binary-Weight-Network version of AlexNet is only 2.9% less than the\n",
    "full-precision AlexNet (in top-1 measure). We compare our method with recent\n",
    "network binarization methods, BinaryConnect and BinaryNets, and outperform\n",
    "these methods by large margins on ImageNet, more than 16% in top-1 accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><img src=\"images/XNOR/fig1.png\" width=\"1000\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Related Work\n",
    "\n",
    "Deep neural networks often suffer from **over-parametrization** and **large amounts of redundancy**\n",
    "in their models. This typically results in inefficient computation and memory\n",
    "usage[12]. Several methods have been proposed to address efficient training and inference\n",
    "in deep neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shallow networks:** Estimating a deep neural network with a shallower model reduces\n",
    "the size of a network. Early theoretical by Cybenko shows a network with a\n",
    "large enough single hidden layer of sigmoid units can approximate any decision boundary\n",
    "[13]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compressing pre-trained deep networks:** Pruning redundant, non-informative\n",
    "weights in a previously trained network reduces the size of the network at inference\n",
    "time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compressing pre-trained deep networks**: Pruning redundant, non-informative\n",
    "weights in a previously trained network reduces the size of the network at inference\n",
    "time. Weight decay [17] was an early method for pruning a network. Optimal Brain\n",
    "Damage [18] and Optimal Brain Surgeon [19] use the **Hessian of the loss function to\n",
    "prune a network by reducing the number of connections**. Recently [20] **reduced the\n",
    "number of parameters by an order of magnitude** in several state-of-the-art neural networks\n",
    "by pruning. [21] proposed to reduce the number of activations for compression\n",
    "and acceleration. Deep compression [22] reduces the storage and energy required to run\n",
    "inference on large networks so they can be deployed on mobile devices. They remove\n",
    "the redundant connections and quantize weights so that multiple connections share the\n",
    "same weight, and then they use **Huffman coding** to compress the weights. **HashedNets**\n",
    "[23] uses a hash function to reduce model size by randomly grouping the weights, such\n",
    "that connections in a hash bucket use a single parameter value. Matrix factorization has\n",
    "4 Rastegari et al.been used by [24,25]. **We are different from these approaches because we do not use a\n",
    "pretrained network. We train binary networks from scratch.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Designing compact layers: Designing compact blocks at each layer of a deep network**\n",
    "can help to save memory and computational costs. Replacing the fully connected\n",
    "layer with global average pooling was examined in the Network in Network architecture\n",
    "[26], GoogLenet[3] and Residual-Net[4], which achieved state-of-the-art results\n",
    "on several benchmarks. The bottleneck structure in Residual-Net [4] has been proposed\n",
    "to reduce the number of parameters and improve speed. **Decomposing 3 × 3 convolutions\n",
    "with two 1 × 1** is used in [27] and resulted in state-of-the-art performance on\n",
    "object recognition. **Replacing 3 × 3 convolutions with 1 × 1 convolutions** is used in\n",
    "[28] to create a very compact neural network that can achieve ∼ 50× reduction in the\n",
    "number of parameters while obtaining high accuracy. Our method is different from this\n",
    "line of work because we use the full network (not the compact version) but with binary\n",
    "parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quantizing parameters**: High precision parameters are not very important in achieving\n",
    "high performance in deep networks. [29] proposed to quantize the weights of fully\n",
    "connected layers in deep network by vector quantization techniques. They showed just\n",
    "thresholding the weight values at zero only decreases the top-1 accuracy on ILSVRC2012\n",
    "by less than %10. [30] proposed a provably polynomial time algorithm for training a\n",
    "sparse networks with +1/0/-1 weights. A fixedpoint implementation of 8-bit integer was\n",
    "compared with 32-bit floating point activations in [31]. Another fixed-point network\n",
    "with ternary weights and 3-bits activations presented by [32]. Quantizing a network\n",
    "with L2 error minimization achieved better accuracy on MNIST and CIFAR-10 datasets\n",
    "in [33]. Back-propagation process by quantizing the representations at each layer of the\n",
    "network was presented in [34] to convert some of the remaining multiplications into\n",
    "binary shifts by restricting the neuron values of power-of-two integers. They carry the\n",
    "full precision weights during the test phase, and only quantize the neurons during the\n",
    "back-propagation process, and not during the forward-propagation. Our work is similar\n",
    "to these methods since we are quantizing the parameters in the network. **But our\n",
    "quantization is the extreme scenario +1,-1.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Binary Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><img src=\"images/XNOR/fig3.png\" width=\"500\"><img src=\"images/XNOR/fig4.png\" width=\"500\"><img src=\"images/XNOR/fig5.png\" width=\"500\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. XNOR-Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><img src=\"images/XNOR/fig6.png\" width=\"500\"><img src=\"images/XNOR/fig7.png\" width=\"500\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><img src=\"images/XNOR/fig2.png\" width=\"600\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><img src=\"images/XNOR/fig8.png\" width=\"600\"></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
